# Awesome-Multi-Modal-Foundation-Models-for-Computational-Pathology

## Multi-Modal Foundation Models for CPath

### Non-LLM-Based

- PLIP — A visual--language foundation model for pathology image analysis using medical Twitter [https://github.com/PathologyFoundation/plip]
- PathCLIP — A generative foundation ai assistant towards artificial general intelligence of pathology [https://github.com/superjamessyx/Generative-Foundation-AI-Assistant-for-Pathology]
- QuiltNet — Quilt-1M: One Million Image-Text Pairs for Histopathology [https://github.com/wisdomikezogwo/quilt1m]
- PathGen-CLIP — PathGen-1.6M: 1.6 Million Pathology Image-text Pairs Generation through Multi-agent Collaboration
- CONCH — A Vision-Language Foundation Model for Computational Pathology [https://github.com/mahmoodlab/CONCH]
- CHIEF — A pathology foundation model for cancer diagnosis and prognosis prediction [https://github.com/hms-dbmi/CHIEF]
- PathAlign: A vision-language model for whole slide images in histopathology
- PRISM: A Multi-Modal Generative Foundation Model for Slide-Level Histopathology
- KEP — Knowledge-enhanced Visual-Language Pretraining for Computational Pathology [https://github.com/MAGIC-AI4Med/KEP]
- MLLM4PUE — Toward Universal Embeddings in Digital Pathology through Multimodal LLMs
- MUSK — A vision–language foundation model for precision oncology
- TITAN — Multimodal Whole Slide Foundation Model for Pathology [https://github.com/mahmoodlab/TITAN]

### LLM-Based

- PathAsst — A generative foundation ai assistant towards artificial general intelligence of pathology [https://github.com/superjamessyx/Generative-Foundation-AI-Assistant-for-Pathology]
- Quilt-LLaVA: Visual Instruction Tuning by Extracting Localized Narratives from Open-Source Histopathology Videos [https://github.com/aldraus/quilt-llava]
- PA-LLaVA: A Large Language-Vision Assistant for Human Pathology Image Understanding [https://github.com/ddw2AIGROUP2CQUPT/PA-LLaVA]
- PathChat — A Foundational Multimodal Vision Language AI Assistant for Human Pathology
- SlideChat — A Large Vision-Language Assistant for Whole-Slide Pathology Image Understanding
- WSI-LLaVA：A Multimodal Large Language Model for Whole Slide Image
- PathInsight: Instruction Tuning of Multimodal Datasets and Models for Intelligence Assisted Diagnosis in Histopathology
- Dr-LLaVA: Visual Instruction Tuning with Symbolic Clinical Grounding
- CLOVER — Cost-effective Instruction Learning for Pathology Vision and Language Analysis
- CPath-Omni: A Unified Multimodal Foundation Model for Patch and Whole Slide Image Analysis in Computational Pathology
- PathGen-LLaVA — PathGen-1.6M: 1.6 Million Pathology Image-text Pairs Generation through Multi-agent Collaboration
- HistoGPT — Generating highly accurate histopathology reports from whole slide images [https://github.com/marrlab/HistoGPT]
